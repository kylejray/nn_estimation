{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0388c999-02dd-4d0e-b8a0-66d89f9c1716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from argparse import Namespace\n",
    "\n",
    "from training import ModelTrainer, TrajectoryGenerator\n",
    "\n",
    "from models import SingleTimeStep\n",
    "\n",
    "from experiments import entropy_loss_TUR, entropy_infer_TUR, force_loss, force_infer\n",
    "from experiments import entropy_loss_ML, entropy_infer_ML\n",
    "\n",
    "\n",
    "\n",
    "from free_diffusion import params, simulate_free_diffusion_underdamped, realepr, traj_dEnt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83b8295-1e48-491c-8c13-b61f74b0e40c",
   "metadata": {},
   "source": [
    "### EXAMPLE TRAIN/INFERENCE IF LOSS IS FOR FORCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3d2b28-7763-4b57-bed8-265def7a5fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_options = Namespace()\n",
    "model_options = Namespace()\n",
    "\n",
    "training_options.n_epoch = 200\n",
    "training_options.epoch_s = 10_000\n",
    "\n",
    "training_options.n_iter = 1\n",
    "training_options.iter_s = 10_000\n",
    "\n",
    "training_options.n_infer = 1\n",
    "training_options.infer_s = 10_000\n",
    "\n",
    "training_options.lr = 1E-4\n",
    "training_options.wd = 1E-5\n",
    "\n",
    "model_options.n_input = 2\n",
    "model_options.n_hidden = 512\n",
    "model_options.n_output = 1\n",
    "# this is how many hidden layers to use\n",
    "model_options.num_inner = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d766584-45ea-4a26-ad39-a95bc0f2730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#params stores information for the sim\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00029ec-64e0-43f2-a9a0-51db48c93ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gamma is the force since we are in free diffusion\n",
    "params['gamma'] = 1\n",
    "\n",
    "#this is the initial distribution params for the free diffusion\n",
    "params['init'] = [1,1,1]\n",
    "\n",
    "# we want to test coarse data, lets say we only see every 10 steps\n",
    "params['coarse'] = 10\n",
    "params['dt'] = .001\n",
    "\n",
    "#how long of a trajectory to simulate \n",
    "# we'll get the force for 1 step only, obviously\n",
    "# it is set to 20 because we need to simulater 20 steps to get one step at coarse = 10 with inferring velocity\n",
    "params['num_steps'] = 20\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9645e013-c876-40a2-8328-7c3a8eeacddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "WeightFunction = SingleTimeStep(model_options)\n",
    "FreeDiffusion = TrajectoryGenerator(simulate_free_diffusion_underdamped, params)\n",
    "\n",
    "#need to set this, so that the simulator knows to return estimated velocity insead of the real one\n",
    "FreeDiffusion.infer_velocity = True\n",
    "\n",
    "optimizer = torch.optim.Adam\n",
    "#optimizer = torch.optim.SGD\n",
    "\n",
    "Force = ModelTrainer(WeightFunction, FreeDiffusion, optimizer, force_loss, force_infer, training_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eedb64-e790-4ea5-883c-2a7eb3ee8da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "untrained_output, untrained_test_trajectories = Force.infer(return_trajectories=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b919a6b9-cfb8-47d3-917c-9b90f3a2a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can edit training options here if you want\n",
    "#training_options.n_epoch = 150\n",
    "#training_options.epoch_s = 10_000\n",
    "#training_options.n_iter = 1\n",
    "#training_options.iter_s = 10_000\n",
    "\n",
    "Force.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f018808d-e53e-4179-9ad7-4c8e0036752c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "plt.close()\n",
    "Force.plot_training_loss(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e73b30-ec3e-4bd8-923d-f1789978174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, test_trajectories = Force.infer(return_trajectories = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7606f96e-d4ae-49a8-bc37-83bdc560c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, sharex=True, sharey=True)\n",
    "vmin, vmax = test_trajectories[0].min(), test_trajectories[0].max()\n",
    "\n",
    "ut_traj = untrained_test_trajectories[0][...,1].ravel()\n",
    "ut_out = untrained_output[0].ravel()\n",
    "\n",
    "tr_traj = test_trajectories[0][...,1].ravel()\n",
    "tr_out = output[0].ravel()\n",
    "\n",
    "ax[0].scatter(ut_traj, ut_out, s=1, alpha=.8, c='r', label='untrained model')\n",
    "ax[1].scatter(tr_traj,tr_out, s=1, alpha=.8,c='b', label='trained model')\n",
    "\n",
    "for i in range(2):\n",
    "    ax[i].plot(np.linspace(vmin,vmax,10),-params['gamma']*np.linspace(vmin,vmax,10), c='k', label='-v*$\\\\gamma$')\n",
    "    ax[i].legend()\n",
    "ax[0].set_xlabel('v')\n",
    "ax[0].set_xlabel('F')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed021405-df88-4442-b793-a443fa7f958b",
   "metadata": {},
   "source": [
    "### EXAMPLE TRAIN/INFERENCE IF LOSS IS FOR EP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6332c370-5f34-4e24-ac9c-ed90c15b6905",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_options = Namespace()\n",
    "model_options = Namespace()\n",
    "\n",
    "training_options.n_epoch = 10\n",
    "training_options.epoch_s = 25_000\n",
    "\n",
    "training_options.n_iter = 5\n",
    "training_options.iter_s = 20_000\n",
    "\n",
    "training_options.n_infer = 20\n",
    "training_options.infer_s = 50_000\n",
    "\n",
    "training_options.lr = 1E-4\n",
    "training_options.wd = 1E-5\n",
    "\n",
    "model_options.n_input = 2\n",
    "model_options.n_hidden = 512\n",
    "model_options.n_output = 1\n",
    "model_options.num_inner = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9274db-065c-45df-aa31-70baf4941dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how long of a trajectory to get the EP for, here we can accomodate more than one step\n",
    "# but it is still rate based ultimately\n",
    "params['num_steps'] = 1\n",
    "\n",
    "#this is the initial distribution params for the free diffusion\n",
    "params['init'] = [.6,.8,.5]\n",
    "\n",
    "\n",
    "#for non coarse data\n",
    "params['coarse'] = 1\n",
    "params['dt'] = .001\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6178bac1-b490-4d1e-b2aa-f7bb481ac9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "WeightFunction = SingleTimeStep(model_options)\n",
    "WeightFunction_ML = SingleTimeStep(model_options)\n",
    "\n",
    "FreeDiffusion = TrajectoryGenerator(simulate_free_diffusion_underdamped, params)\n",
    "\n",
    "#by default, velocity is not inferred so no need to change\n",
    "print('inferring velocity:',FreeDiffusion.infer_velocity)\n",
    "\n",
    "optimizer = torch.optim.Adam\n",
    "\n",
    "#instead of testing corase grained data, let's see the difference between the TUR based and ML based methods:\n",
    "\n",
    "# old loss/inference based on TUR\n",
    "EntProd = ModelTrainer(WeightFunction, FreeDiffusion, optimizer, entropy_loss_TUR, entropy_infer_TUR, training_options)\n",
    "# new loss/inference based on ML\n",
    "EntProd_ML = ModelTrainer(WeightFunction_ML, FreeDiffusion, optimizer, entropy_loss_ML, entropy_infer_ML, training_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f287dd3c-106f-431a-9a91-005588e8952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EntProd.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03400556",
   "metadata": {},
   "outputs": [],
   "source": [
    "EntProd_ML.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7ded52-0be0-491f-aaed-31e5871053b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "plt.close()\n",
    "EntProd.plot_training_loss(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cb7f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "plt.close()\n",
    "EntProd_ML.plot_training_loss(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb58d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_ML= EntProd_ML.infer(return_trajectories=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443ef29d-8e10-4262-85f9-81ebee87bda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = EntProd.infer(return_trajectories=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec4dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ea047",
   "metadata": {},
   "outputs": [],
   "source": [
    "int(params['num_steps']/params['coarse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dca65b7-1c94-4410-aebb-d3a868cc02c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating real average EP \n",
    "resolution = 1_000\n",
    "T = params['Dt']*( int( (params['num_steps']+1)/params['coarse'])-1)\n",
    "ents = realepr( np.linspace(0, T, resolution),*params['init'] )*(T/resolution)\n",
    "ent_production = sum(ents)\n",
    "print(ent_production)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167bf080",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, sharex=True, sharey=True)\n",
    "\n",
    "\n",
    "error_ML = np.array(output_ML)/ent_production - 1\n",
    "error_TUR = np.array(output)/ent_production - 1\n",
    "\n",
    "for i, error in enumerate([error_ML, error_TUR]):\n",
    "    m, s = np.mean(error), np.std(error)\n",
    "    s /= np.sqrt(len(error))\n",
    "    ax[i].plot(error, linestyle='none', marker='D')\n",
    "\n",
    "    for l in [m, m-3*s, m+3*s]:\n",
    "        ax[i].axhline(l, c='k', linewidth=.75)\n",
    "\n",
    "    ax[i].set_xlabel('trial')\n",
    "    ax[i].set_ylabel('relative error')\n",
    "\n",
    "    ax[i].axhline(0, c='k', linestyle='--', linewidth=2)\n",
    "\n",
    "ax[0].set_title('ML loss/inference')\n",
    "ax[1].set_title('TUT loss/inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e06ba6-4d89-4340-8514-e9a9075ed5af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
